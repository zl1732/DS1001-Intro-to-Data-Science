{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import codecs\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleanText(text):\n",
    "    # This function takes in a text string and cleans it \n",
    "    # by keeping only alphanumeric and common punctuations\n",
    "    # Returns the cleaned string\n",
    "    clean_text = text.replace('\\n','').replace('\\r','')\n",
    "    clean_text = re.sub(r'[^a-zA-Z0-9.:!? ]','',clean_text)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def readEmail(path):\n",
    "    # This function takes a path to an email text file\n",
    "    # Returns a tuple of the subject line and the body text\n",
    "    with codecs.open(path, \"r\",encoding='utf-8', errors='ignore') as f:\n",
    "        subject = cleanText(f.readline()[9:])\n",
    "        body = cleanText(f.read())\n",
    "        return [subject, body]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subjects = []\n",
    "bodys = []\n",
    "spam = []\n",
    "# read hams\n",
    "for filename in os.listdir(\"enron1/ham\"):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        subject, body = readEmail(\"enron1/ham/\"+filename)\n",
    "        subjects.append(subject)\n",
    "        bodys.append(body)\n",
    "        spam.append(0)\n",
    "# read spams\n",
    "for filename in os.listdir(\"enron1/spam\"):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        subject, body = readEmail(\"enron1/spam/\"+filename)\n",
    "        subjects.append(subject)\n",
    "        bodys.append(body)\n",
    "        spam.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "data['subject'] = subjects\n",
    "data['body'] = bodys\n",
    "data['spam'] = spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>christmas tree farm pictures</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vastar resources  inc .</td>\n",
       "      <td>gary  production from the high island larger b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>calpine daily gas nomination</td>\n",
       "      <td>calpine daily gas nomination 1 . doc</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>re : issue</td>\n",
       "      <td>fyi  see note below  already done .stella     ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>meter 7268 nov allocation</td>\n",
       "      <td>fyi .                      forwarded by lauri ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        subject  \\\n",
       "0  christmas tree farm pictures   \n",
       "1       vastar resources  inc .   \n",
       "2  calpine daily gas nomination   \n",
       "3                    re : issue   \n",
       "4     meter 7268 nov allocation   \n",
       "\n",
       "                                                body  spam  \n",
       "0                                                        0  \n",
       "1  gary  production from the high island larger b...     0  \n",
       "2               calpine daily gas nomination 1 . doc     0  \n",
       "3  fyi  see note below  already done .stella     ...     0  \n",
       "4  fyi .                      forwarded by lauri ...     0  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tokenize\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "import string\n",
    "tokenizer = WordPunctTokenizer()\n",
    "new_body = []\n",
    "for body in data['body']:\n",
    "    wtks = tokenizer.tokenize(body)\n",
    "    new_body.append([wtk for wtk in wtks if wtk not in string.punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "      <th>spam</th>\n",
       "      <th>tokens</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>christmas tree farm pictures</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vastar resources  inc .</td>\n",
       "      <td>gary  production from the high island larger b...</td>\n",
       "      <td>0</td>\n",
       "      <td>[gary, production, from, the, high, island, la...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>calpine daily gas nomination</td>\n",
       "      <td>calpine daily gas nomination 1 . doc</td>\n",
       "      <td>0</td>\n",
       "      <td>[calpine, daily, gas, nomination, 1, doc]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>re : issue</td>\n",
       "      <td>fyi  see note below  already done .stella     ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[fyi, see, note, below, already, done, stella,...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>meter 7268 nov allocation</td>\n",
       "      <td>fyi .                      forwarded by lauri ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[fyi, forwarded, by, lauri, a, allen, hou, ect...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        subject  \\\n",
       "0  christmas tree farm pictures   \n",
       "1       vastar resources  inc .   \n",
       "2  calpine daily gas nomination   \n",
       "3                    re : issue   \n",
       "4     meter 7268 nov allocation   \n",
       "\n",
       "                                                body  spam  \\\n",
       "0                                                        0   \n",
       "1  gary  production from the high island larger b...     0   \n",
       "2               calpine daily gas nomination 1 . doc     0   \n",
       "3  fyi  see note below  already done .stella     ...     0   \n",
       "4  fyi .                      forwarded by lauri ...     0   \n",
       "\n",
       "                                              tokens  idx  \n",
       "0                                                 []    0  \n",
       "1  [gary, production, from, the, high, island, la...    1  \n",
       "2          [calpine, daily, gas, nomination, 1, doc]    2  \n",
       "3  [fyi, see, note, below, already, done, stella,...    3  \n",
       "4  [fyi, forwarded, by, lauri, a, allen, hou, ect...    4  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tokens'] = new_body\n",
    "data['idx'] = np.arange(data.shape[0])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "from gensim import utils\n",
    "import gensim.utils\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences = data.apply(lambda row : LabeledSentence(row['tokens'],[row['spam']]), axis = 1)\n",
    "d2v_model = Doc2Vec(min_count = 1, window = 10, size=100, sample=1e-4, negative=5, workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d2v_model.build_vocab(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    d2v_model.train(sentences.reindex(np.random.permutation(sentences.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d2v_model.save('test.d2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('now', 0.4317642152309418),\n",
       " ('discount', 0.4178639054298401),\n",
       " ('store', 0.39517587423324585),\n",
       " ('biggest', 0.3790737986564636),\n",
       " ('load', 0.37169861793518066),\n",
       " ('spoil', 0.367867112159729),\n",
       " ('a', 0.36497950553894043),\n",
       " ('hotel', 0.36494749784469604),\n",
       " ('site', 0.3580681383609772),\n",
       " ('visit', 0.35701173543930054)]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2v_model.most_similar('hurry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
